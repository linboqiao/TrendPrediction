{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data shape:', (296104, 93))\n",
      "('data_X shape:', (296104, 88))\n",
      "('data_Y shape:', (296104,))\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = np.loadtxt('../data/stock_train_data_20170916.csv',delimiter=',',skiprows=1)\n",
    "print('data shape:', data.shape)\n",
    "\n",
    "# data preprocessing\n",
    "np.random.shuffle(data)\n",
    "data_X = data[:,1:89]\n",
    "data_Y = data[:,90]\n",
    "weight_samples = data[:,89]\n",
    "group_samples = data[:,91]\n",
    "era_samples = data[:,92]\n",
    "scaler = preprocessing.StandardScaler().fit(data_X)\n",
    "data_X = scaler.transform(data_X)\n",
    "data_cv = xgb.DMatrix(data_X, data_Y, weight = weight_samples)\n",
    "print('data_X shape:', data_X.shape)\n",
    "print('data_Y shape:', data_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation\n",
      "[0]\ttrain-error:0.403546+0.00148194\ttest-error:0.409174+0.00412982\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 3 rounds.\n",
      "[1]\ttrain-error:0.39445+0.00151339\ttest-error:0.40126+0.00429095\n",
      "[2]\ttrain-error:0.388199+0.00205108\ttest-error:0.395298+0.00442949\n",
      "[3]\ttrain-error:0.385784+0.000672063\ttest-error:0.393855+0.00359058\n",
      "[4]\ttrain-error:0.38257+0.000797252\ttest-error:0.390826+0.00385503\n",
      "[5]\ttrain-error:0.380341+0.000644967\ttest-error:0.389023+0.00353434\n",
      "[6]\ttrain-error:0.378363+0.00119459\ttest-error:0.38773+0.0030115\n",
      "[7]\ttrain-error:0.376655+0.00150333\ttest-error:0.386554+0.00331316\n",
      "[8]\ttrain-error:0.375058+0.00133812\ttest-error:0.38551+0.00305468\n",
      "[9]\ttrain-error:0.373618+0.00158427\ttest-error:0.384502+0.00370604\n",
      "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      "0         0.409174        0.004130          0.403546         0.001482\n",
      "1         0.401260        0.004291          0.394450         0.001513\n",
      "2         0.395298        0.004429          0.388199         0.002051\n",
      "3         0.393855        0.003591          0.385784         0.000672\n",
      "4         0.390826        0.003855          0.382570         0.000797\n",
      "5         0.389023        0.003534          0.380341         0.000645\n",
      "6         0.387730        0.003012          0.378363         0.001195\n",
      "7         0.386554        0.003313          0.376655         0.001503\n",
      "8         0.385510        0.003055          0.375058         0.001338\n",
      "9         0.384502        0.003706          0.373618         0.001584\n",
      "('time elapse:', 132.11761093139648)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# logistic regression for binary classification. Output probability.\n",
    "param['objective'] = 'binary:logistic' \n",
    "param['metrics'] = {'logloss'}\n",
    "param['eta'] = 0.1          # step size of each boosting step\n",
    "param['max_depth'] = 6       # maximum depth of the tree\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 7\n",
    "param['seed'] = 0\n",
    "param['nrounds'] = 10\n",
    "#param['eval_metric'] = \"auc\"\n",
    "# https://rdrr.io/cran/xgboost/man/xgb.train.html\n",
    "# https://www.cnblogs.com/haobang008/p/5909207.html\n",
    "\n",
    "start = time.time();\n",
    "print ('running cross validation')\n",
    "# do cross validation, this will print result out as\n",
    "# [iteration]  metric_name:mean_value+std_value\n",
    "# std_value is standard deviation of the metric\n",
    "res = xgb.cv(param, data_cv,      \n",
    "             nfold=10,\n",
    "             callbacks=[xgb.callback.print_evaluation(show_stdv=True),\n",
    "                        xgb.callback.early_stop(3)])\n",
    "end = time.time();\n",
    "print (res)\n",
    "print('time elapse:', end- start);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data_X shape:', (296104, 88))\n",
      "('data_Y shape:', (296104,))\n",
      "('train_X', (266493, 88))\n",
      "('test_X', (29611, 88))\n",
      "[0]\ttrain-error:0.402851\ttest-error:0.408325\n",
      "[1]\ttrain-error:0.39202\ttest-error:0.400858\n",
      "[2]\ttrain-error:0.389724\ttest-error:0.397337\n",
      "[3]\ttrain-error:0.383937\ttest-error:0.391529\n",
      "[4]\ttrain-error:0.380668\ttest-error:0.390403\n",
      "[5]\ttrain-error:0.378342\ttest-error:0.389599\n",
      "[6]\ttrain-error:0.376909\ttest-error:0.388194\n",
      "[7]\ttrain-error:0.374857\ttest-error:0.385298\n",
      "[8]\ttrain-error:0.372221\ttest-error:0.382285\n",
      "[9]\ttrain-error:0.370998\ttest-error:0.380321\n",
      "('time elapse train:', 16.8576500415802)\n",
      "('time elapse predict:', 0.0061647891998291016)\n",
      "[ 0.54060709  0.58983809  0.53249854 ...,  0.59247029  0.57125658\n",
      "  0.73460591]\n",
      "('error:', 0.52521022592955324)\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "per_train = 0.9\n",
    "# data preprocessing\n",
    "#np.random.shuffle(data)\n",
    "# rebuild the data with era (time)\n",
    "\n",
    "data_X = data[:,1:89]\n",
    "data_Y = data[:,90]\n",
    "weight_samples = data[:,89]\n",
    "group_samples = data[:,91].reshape(-1,1)\n",
    "era_samples = data[:,92]\n",
    "\n",
    "#data_X = np.append(data_X, group_samples, axis= 1)\n",
    "scaler = preprocessing.StandardScaler().fit(data_X)\n",
    "data_X = scaler.transform(data_X)\n",
    "data_cv = xgb.DMatrix(data_X, data_Y, weight = weight_samples)\n",
    "print('data_X shape:', data_X.shape)\n",
    "print('data_Y shape:', data_Y.shape)\n",
    "\n",
    "# more work needed for traing set selection...\n",
    "test_X = data_X[int(data_X.shape[0] * per_train):]\n",
    "test_Y = data_Y[int(data_X.shape[0] * per_train):]\n",
    "weight_test = weight_samples[int(data_X.shape[0] * per_train):]\n",
    "train_X = data_X[0:int(data_X.shape[0] * per_train)]\n",
    "train_Y = data_Y[0:int(data_X.shape[0] * per_train)]\n",
    "weight_train = weight_samples[0:int(data_X.shape[0] * per_train)]\n",
    "print(\"train_X\",train_X.shape)\n",
    "print(\"test_X\",test_X.shape)\n",
    "\n",
    "xg_train = xgb.DMatrix( train_X, label=train_Y, weight = weight_train)\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y, weight = weight_test)\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "\n",
    "num_round = 10\n",
    "start = time.time();\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist);\n",
    "end = time.time();\n",
    "print('time elapse train:', end- start);\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "start = time.time();\n",
    "y_pred = bst.predict( xg_test )\n",
    "end = time.time();\n",
    "print('time elapse predict:', end- start);\n",
    "print(y_pred)\n",
    "print('error:', np.sum(test_Y == (y_pred > 0)).astype(float) / test_Y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapse predict:', 0.048657894134521484)\n"
     ]
    }
   ],
   "source": [
    "data_to_Predict = np.loadtxt('../data/stock_test_data_20170916.csv',delimiter=',',skiprows=1)\n",
    "ids = data_to_Predict[:,0]\n",
    "test_X = data_to_Predict[:,1:-1]\n",
    "test_X = xgb.DMatrix(test_X)\n",
    "\n",
    "start = time.time();\n",
    "yprob = bst.predict( test_X )\n",
    "end = time.time();\n",
    "print('time elapse predict:', end- start);\n",
    "\n",
    "data_pred = np.concatenate((data_to_Predict[:,0].reshape(yprob.shape[0],-1), yprob.reshape(yprob.shape[0],-1)), axis=1)\n",
    "\n",
    "f = open('./data_pred.csv', 'w')\n",
    "f.write('id,proba\\n')\n",
    "for i in range(data_pred.shape[0]):\n",
    "    s = '%d,%.5f\\n'%(data_pred[i,0], data_pred[i,1])\n",
    "    f.write(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
